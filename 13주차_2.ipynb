{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlJA/X/UGNbKvidWdJoCc6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leetaebeom/python_tb/blob/main/13%EC%A3%BC%EC%B0%A8_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHtGGo3pXyW2"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# 예시 ISBN 리스트 (테스트용으로 3개만)\n",
        "isbn_list = [\"9788960777330\", \"9788968481475\", \"9788998139766\"]\n",
        "\n",
        "# 쪽수와 저자 정보 함께 추출하는 함수\n",
        "def get_page_author(isbn):\n",
        "    url = f\"https://search.kyobobook.co.kr/web/search?vPstrKeyWord={isbn}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        res = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(res.text, 'html.parser')\n",
        "\n",
        "        # 1. 도서 상세 페이지 링크 추출\n",
        "        link_tag = soup.select_one(\"div.title > a\")\n",
        "        if not link_tag:\n",
        "            return None, None\n",
        "        detail_link = \"https://search.kyobobook.co.kr\" + link_tag.get(\"href\")\n",
        "\n",
        "        # 2. 상세 페이지 접근\n",
        "        detail_res = requests.get(detail_link, headers=headers)\n",
        "        detail_soup = BeautifulSoup(detail_res.text, 'html.parser')\n",
        "\n",
        "        # 3. 쪽수와 저자 추출\n",
        "        page = None\n",
        "        author = None\n",
        "        info_list = detail_soup.select(\"div.publish-info > ul > li\")\n",
        "\n",
        "        for li in info_list:\n",
        "            text = li.text.strip()\n",
        "            if \"쪽수\" in text:\n",
        "                page = text.split(\":\")[-1].strip().replace(\"쪽\", \"\")\n",
        "            if \"저자\" in text or \"글쓴이\" in text:\n",
        "                author = li.select_one(\"a\").text.strip()\n",
        "\n",
        "        return page, author\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "# 결과 저장\n",
        "results = []\n",
        "\n",
        "for isbn in isbn_list:\n",
        "    page, author = get_page_author(isbn)\n",
        "    results.append({\n",
        "        \"ISBN\": isbn,\n",
        "        \"Page\": page,\n",
        "        \"Author\": author\n",
        "    })\n",
        "    time.sleep(1)  # 과도한 요청 방지\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame(results)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_book_info(isbn):\n",
        "    url = f\"https://search.kyobobook.co.kr/web/search?vPstrKeyWord={isbn}\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "    try:\n",
        "        res = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(res.text, 'html.parser')\n",
        "        link_tag = soup.select_one(\"div.title > a\")\n",
        "        if not link_tag:\n",
        "            return None, None, None\n",
        "        detail_link = \"https://search.kyobobook.co.kr\" + link_tag.get(\"href\")\n",
        "\n",
        "        detail_res = requests.get(detail_link, headers=headers)\n",
        "        detail_soup = BeautifulSoup(detail_res.text, 'html.parser')\n",
        "\n",
        "        page = size = author = None\n",
        "        info_list = detail_soup.select(\"div.publish-info > ul > li\")\n",
        "\n",
        "        for li in info_list:\n",
        "            text = li.text.strip()\n",
        "            if \"쪽수\" in text:\n",
        "                page = text.split(\":\")[-1].strip().replace(\"쪽\", \"\")\n",
        "            elif \"크기\" in text:\n",
        "                size = text.split(\":\")[-1].strip()\n",
        "            elif \"저자\" in text:\n",
        "                author = li.select_one(\"a\").text.strip()\n",
        "\n",
        "        return page, size, author\n",
        "    except:\n",
        "        return None, None, None\n"
      ],
      "metadata": {
        "id": "eLyT6nX5X1H_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}